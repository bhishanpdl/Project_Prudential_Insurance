{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "b05_prudential_modelling_xgboost_linear_poisson_reg_offset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmU7v5L4Y0eB",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Kernel Author:</b>  <br>\n",
        "<a href=\"https://bhishanpdl.github.io/\" , target=\"_blank\">Bhishan Poudel, Ph.D Astrophysics</a> .\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSgj0OppY46P",
        "colab_type": "text"
      },
      "source": [
        "# Description\n",
        "In this project we will use multiclass classification to predict one of the 8 possible value of Response.\n",
        "\n",
        "The data is taken from Kaggle Prudential Life Insurance Project.\n",
        "\n",
        "About only 40% household in USA has life insurance policy. Based on different of applicant 8 different quotes are granted to applicants.\n",
        "\n",
        "Here category 8 has the highest counts, I assume it the quote that is granted.\n",
        "```\n",
        "Records: 60k\n",
        "Features: 127\n",
        "Target: Response (has 8 categories, 1-8)\n",
        "\n",
        "```\n",
        "\n",
        "Features:\n",
        "```\n",
        "1 Misc             : Age ht wt bmi              4\n",
        "2 Product Info     : Product_Info_1 to 7        7\n",
        "3 Employment Info  : Employment_Info_1 to 6     6\n",
        "4 Insured Info     : InsuredInfo_1 to 7         7\n",
        "5 Insurance History: Insurance_History_1 to 9   9\n",
        "6 Family History   : Family_Hist_1 to 5         5\n",
        "7 Medical History  : Medical_History_1 to 41    41\n",
        "8 Medical Keywords : Medical_Keyword_1 to 48    48\n",
        "Target: Response                                1\n",
        "ID    : ID                                      1\n",
        "---------------------------------------------------\n",
        "Total Features: 127\n",
        "Dependent Variable: 1 (Response)\n",
        "```\n",
        "\n",
        "Method Used:\n",
        "- XGBoost\n",
        "\n",
        "Metric Used:\n",
        "- Weighted Quadratic Kappa (cohehs kappa with weight equals quadratic)\n",
        "\n",
        "**References**  \n",
        "- https://www.kaggle.com/zeroblue/xgboost-with-optimized-offsets\n",
        "\n",
        "**Notes about offset**  \n",
        "Here, in this project the metric of evaluation is kappa. But when we fit the linear regression using xgboost the loss function is squared error (MSE). The predictions given by optimizing MSE may not be optimal for the evaluation metric kappa. \n",
        "\n",
        "For the ordinal ranking metric such as kappa, we assume there is parameter space which is more suitable to predictions if we offset the predictions given by MSE. For example, a prediction 1.6 from MSE belongs to class 2. But if we had a offset of 1 for that prediction, then 1.6+1 = 2.6, which becomes class 3. By changing the class we may achieve the better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB4VFyugZO3S",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwYMwzLY-Rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "5c4bca9c-9a23-4f5e-ba06-3e1020755721"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('ggplot') \n",
        "SEED=100\n",
        "home = os.path.expanduser('~')\n",
        "time_start_notebook = time.time()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from scipy.optimize import fmin_powell\n",
        "import xgboost as xgb\n",
        "xgb.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.90'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfYzhKH2qiK",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne7Ug1EEdbVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26e35d62-ac31-448a-e4d9-6042a6eaf28c"
      },
      "source": [
        "def data_cleaning():\n",
        "    df = pd.read_csv('https://github.com/bhishanpdl/Datasets/blob/master/Prudential_Insurance/raw/train.csv.zip?raw=true',compression='zip')\n",
        "    columns_to_drop = ['Id', 'Medical_History_10','Medical_History_24']\n",
        "    df = df.drop(columns_to_drop,axis=1)\n",
        "    df['Product_Info_2_char'] = df.Product_Info_2.str[0]\n",
        "    df['Product_Info_2_num'] = df.Product_Info_2.str[1]\n",
        "\n",
        "    # factorize categorical variables\n",
        "    df['Product_Info_2'] = pd.factorize(df['Product_Info_2'])[0]\n",
        "    df['Product_Info_2_char'] = pd.factorize(df['Product_Info_2_char'])[0]\n",
        "    df['Product_Info_2_num'] = pd.factorize(df['Product_Info_2_num'])[0]\n",
        "\n",
        "    df['BMI_Age'] = df['BMI'] * df['Ins_Age']\n",
        "\n",
        "    med_keyword_columns = df.columns[df.columns.str.startswith('Medical_Keyword_')]\n",
        "    df['Med_Keywords_Count'] = df[med_keyword_columns].sum(axis=1)\n",
        "    df = df.fillna(-1)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = data_cleaning()\n",
        "print(df.shape)\n",
        "df.isna().sum().sum(), df.sum().sum()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(59381, 129)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 26897356.818315115)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQMoFYd-cVK2",
        "colab_type": "text"
      },
      "source": [
        "# Train Test Split with Stratify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCGB7MqdTgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "target = 'Response'\n",
        "df_Xtrain, df_Xtest, ser_ytrain, ser_ytest = train_test_split(\n",
        "    df.drop(target,axis=1), df[target],\n",
        "    test_size=0.2, random_state=SEED, stratify=df[target])\n",
        "\n",
        "\n",
        "ytrain = ser_ytrain.to_numpy().ravel()\n",
        "ytest = ser_ytest.to_numpy().ravel()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c74kddn0R03g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtrain = xgb.DMatrix(df_Xtrain, label=ser_ytrain)\n",
        "dtest = xgb.DMatrix(df_Xtest, label=ser_ytest)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBvntjMcnnZm",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGmT2kLFnpuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_wrapper(y, yhat):\n",
        "    # cohens kappa is symmetrics. y <=> yhat gives same result.\n",
        "    y = np.array(y).astype(int)\n",
        "    yhat = np.array(yhat)\n",
        "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
        "    return metrics.cohen_kappa_score(y, yhat,weights='quadratic')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbqoC9vsxj7f",
        "colab_type": "text"
      },
      "source": [
        "# Useful Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-9RjSFpxl7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def apply_offsets(offsets,preds):\n",
        "    (x1,x2,x3,x4,x5,x6,x7) = offsets  \n",
        "    res = []\n",
        "    for y in list(preds):\n",
        "        if y < x1:\n",
        "            res.append(1)\n",
        "        elif y < x2:\n",
        "            res.append(2)\n",
        "        elif y < x3:\n",
        "            res.append(3)\n",
        "        elif y < x4:\n",
        "            res.append(4)\n",
        "        elif y < x5:\n",
        "            res.append(5)\n",
        "        elif y < x6:\n",
        "            res.append(6)\n",
        "        elif y < x7:\n",
        "            res.append(7)\n",
        "        else: res.append(8)\n",
        "    return res"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6bBxxBIxmfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def digitize_train(guess_lst,train_preds):\n",
        "    (x1,x2,x3,x4,x5,x6,x7) = list(guess_lst)   \n",
        "    res = []\n",
        "    for y in list(train_preds):\n",
        "        if y < x1:\n",
        "            res.append(1)\n",
        "        elif y < x2:\n",
        "            res.append(2)\n",
        "        elif y < x3:\n",
        "            res.append(3)\n",
        "        elif y < x4:\n",
        "            res.append(4)\n",
        "        elif y < x5:\n",
        "            res.append(5)\n",
        "        elif y < x6:\n",
        "            res.append(6)\n",
        "        elif y < x7:\n",
        "            res.append(7)\n",
        "        else: res.append(8)\n",
        "    return res"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFvvbEuux2n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_offsets_minimizing_train_preds_kappa(guess_lst):\n",
        "    res = digitize_train(guess_lst,train_preds)\n",
        "    return -quadratic_weighted_kappa(ytrain, res) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS1ly03e1I78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_eval = pd.DataFrame({'Model': [],\n",
        "                        'TrainKappa': [],\n",
        "                        'TestKappa' : []})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIWQJS1YZjzw",
        "colab_type": "text"
      },
      "source": [
        "# Modelling xgboost classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZa_wP7qAImQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f788d35-a9c2-4850-d394-21f911f2877c"
      },
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgboost.__version__"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.90'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwAWGNBy4u1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_dict = {'objective': 'reg:squarederror',\n",
        "              'eta': 0.05,\n",
        "              'min_child_weight': 240,\n",
        "              'subsample': 0.9,\n",
        "              'colsample_bytree': 0.67,\n",
        "              'max_depth': 6\n",
        "}\n",
        "xgb_num_rounds = 800"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxADxecf49kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ce2ff94d-b119-47cf-eec4-7ba2e82435b6"
      },
      "source": [
        "%%time\n",
        "bst = xgb.train(params_dict, dtrain, xgb_num_rounds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 56s, sys: 200 ms, total: 3min 57s\n",
            "Wall time: 1min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYrqlZ8r9FHu",
        "colab_type": "text"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zftfm_ni6w8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "e24cb9d8-2eb5-447b-c4d0-3f027e4b8087"
      },
      "source": [
        "# get preds\n",
        "train_preds = bst.predict(dtrain, ntree_limit=bst.best_iteration)\n",
        "test_preds = bst.predict(dtest, ntree_limit=bst.best_iteration)\n",
        "\n",
        "train_kappa = eval_wrapper(ytrain,train_preds)\n",
        "test_kappa = eval_wrapper(ytest, test_preds)\n",
        "\n",
        "row = ['xgb reg', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "df_eval"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>TrainKappa</th>\n",
              "      <th>TestKappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xgb reg</td>\n",
              "      <td>0.669183</td>\n",
              "      <td>0.60401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Model  TrainKappa  TestKappa\n",
              "0  xgb reg    0.669183    0.60401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAQtSPUY9QzG",
        "colab_type": "text"
      },
      "source": [
        "# Find Offsets for Train\n",
        "- https://www.kaggle.com/c/prudential-life-insurance-assessment/discussion/19003\n",
        "- https://github.com/zhurak/kaggle-prudential/blob/master/code/predict.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmOAxXyAFh_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8dadb77b-7e0c-465c-9a22-798ff082783e"
      },
      "source": [
        "%%time\n",
        "\"\"\"\n",
        "Here, we already have train predictions.\n",
        "For these train predictions, if we compare them with original train labels,\n",
        "we get some kappa value. But we want to change the train predictions such\n",
        "that when comparing this changed train prediction with original train labels\n",
        "we get better kappa.\n",
        "\n",
        "For that we use scipy function \"fmin_powell\". The function needs some initial\n",
        "guess so that it can give better offset next time. The default guess is 0.5.\n",
        "For 8 classes (1-8) we can start with (1.5,2.5,...,8.5) then use the result\n",
        "and run the function again.\n",
        "\n",
        "\"\"\";\n",
        "x0 = (1.5,2.9,3.1,4.5,5.5,6.1,7.1)    # initial guess \n",
        "# offsets = fmin_powell(get_offsets_minimizing_train_preds_kappa, x0, disp = True)\n",
        "\n",
        "offsets = [3.117688855474597, 3.574261600706765, 4.347222327043992, \n",
        "           4.919148133534166, 5.529077199779955, 6.1623013715330766, \n",
        "           6.826617448466462]\n",
        "print(list(offsets))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.117688855474597, 3.574261600706765, 4.347222327043992, 4.919148133534166, 5.529077199779955, 6.1623013715330766, 6.826617448466462]\n",
            "CPU times: user 336 µs, sys: 1e+03 ns, total: 337 µs\n",
            "Wall time: 343 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBxtknpjIdCK",
        "colab_type": "text"
      },
      "source": [
        "# Model evaluation after applying offset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT3uAqfuHebc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "b73fd8b3-f48d-49c0-894a-e3c69f5e81d9"
      },
      "source": [
        "train_preds = apply_offsets(offsets,train_preds)\n",
        "train_kappa = quadratic_weighted_kappa(ytrain,train_preds)\n",
        "\n",
        "test_preds = apply_offsets(offsets,test_preds)\n",
        "test_kappa = quadratic_weighted_kappa(ytest,test_preds)\n",
        "\n",
        "row = ['xgb reg + offset', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "df_eval"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>TrainKappa</th>\n",
              "      <th>TestKappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xgb reg</td>\n",
              "      <td>0.669183</td>\n",
              "      <td>0.604010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xgb reg + offset</td>\n",
              "      <td>0.720997</td>\n",
              "      <td>0.651084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Model  TrainKappa  TestKappa\n",
              "0           xgb reg    0.669183   0.604010\n",
              "1  xgb reg + offset    0.720997   0.651084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OVkJmkkcpAo",
        "colab_type": "text"
      },
      "source": [
        "# Using Poission Regression\n",
        "\n",
        "```python\n",
        "objective = \"count:poisson\"\n",
        "\n",
        "```\n",
        "- [poisson intuition](https://www.kaggle.com/c/prudential-life-insurance-assessment/discussion/17803)\n",
        "- [4th place solution](https://www.kaggle.com/c/prudential-life-insurance-assessment/discussion/18996)\n",
        "\n",
        "Who buys life insurance?\n",
        "- Future planning individual.\n",
        "- Company buys for thier employees.\n",
        "\n",
        "Poisson regression is used with COUNT data. And COUNT data describes frequencies of occurrence of a given event/element. In case of this competition, as I understand it, \"Response\" column should be treated more like a categorical one. Or, if we treat it as a numerical one, some generalized linear models (regressions in general) seem to be more intuitive than Poisson distribution.\n",
        "\n",
        "One of Poisson distribution's assumption is that the mean and variance of the distribution are equal. If we take a look at the mean and variance for \"Response\" in train set, they are NOT close.\n",
        "Its counter intutive but still works good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJT7yWXycoT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e33618c1-3919-4fc7-cbec-bad1ec035ca9"
      },
      "source": [
        "ytrain.mean(), ytrain.std()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.636767430111148, 2.4568669703520585)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE6TxpJvdZXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_dict = {'objective': 'count:poisson',\n",
        "              'eta': 0.05,\n",
        "              'min_child_weight': 240,\n",
        "              'subsample': 0.9,\n",
        "              'colsample_bytree': 0.67,\n",
        "              'max_depth': 6\n",
        "}\n",
        "xgb_num_rounds = 800"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "795CS0fMdzoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1b1284b1-f9bf-48e5-b131-69df0b881c2c"
      },
      "source": [
        "%%time\n",
        "bst = xgb.train(params_dict, dtrain, xgb_num_rounds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 3s, sys: 127 ms, total: 4min 3s\n",
            "Wall time: 2min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOeMYocHd47J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "c8b16910-8306-4a83-d7e7-eaabe260c0ff"
      },
      "source": [
        "# model evaluation for regressor\n",
        "train_preds = bst.predict(dtrain, ntree_limit=bst.best_iteration)\n",
        "test_preds = bst.predict(dtest, ntree_limit=bst.best_iteration)\n",
        "train_kappa = eval_wrapper(ytrain,train_preds)\n",
        "test_kappa = eval_wrapper(ytest,  test_preds)\n",
        "\n",
        "row = ['xgb poisson', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "\n",
        "# model evaluation for offset\n",
        "train_preds = apply_offsets(offsets,train_preds)\n",
        "train_kappa = eval_wrapper(ytrain,train_preds)\n",
        "\n",
        "test_preds = apply_offsets(offsets,test_preds)\n",
        "test_kappa = eval_wrapper(ytest,test_preds)\n",
        "\n",
        "row = ['xgb poisson + offset', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "df_eval"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>TrainKappa</th>\n",
              "      <th>TestKappa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xgb reg</td>\n",
              "      <td>0.669183</td>\n",
              "      <td>0.604010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xgb reg + offset</td>\n",
              "      <td>0.720997</td>\n",
              "      <td>0.651084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xgb poisson</td>\n",
              "      <td>0.681906</td>\n",
              "      <td>0.610618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xgb poisson + offset</td>\n",
              "      <td>0.734726</td>\n",
              "      <td>0.654119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model  TrainKappa  TestKappa\n",
              "0               xgb reg    0.669183   0.604010\n",
              "1      xgb reg + offset    0.720997   0.651084\n",
              "2           xgb poisson    0.681906   0.610618\n",
              "3  xgb poisson + offset    0.734726   0.654119"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfJ8nA-JiTmT",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble Voting Regressor\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html\n",
        "\n",
        "A voting regressor is an ensemble meta-estimator that fits several base regressors, each on the whole dataset. Then it averages the individual predictions to form a final prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FaitJHzstUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingRegressor"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDmjI2wQiTvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {'eta': 0.05,\n",
        "              'min_child_weight': 240,\n",
        "              'subsample': 0.9,\n",
        "              'colsample_bytree': 0.67,\n",
        "              'max_depth': 6,\n",
        "              'random_state': SEED\n",
        "}\n",
        "xgb_num_rounds = 800"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXvtkUdFiTsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_xgb_reg = xgb.XGBRegressor(objective='reg:squarederror',**params)\n",
        "model_xgb_psn = xgb.XGBRegressor(objective='count:poisson',**params)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O78xWHhIiTp5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "c35bb12b-c165-4874-f8d2-a1fdfcf3c5af"
      },
      "source": [
        "estimators = [('model1',model_xgb_reg),\n",
        "              ('model2',model_xgb_psn)]\n",
        "\n",
        "ensemble = VotingRegressor(estimators=estimators,n_jobs=-1,weights=[1,1])\n",
        "\n",
        "ensemble.fit(df_Xtrain, ser_ytrain)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingRegressor(estimators=[('model1',\n",
              "                             XGBRegressor(base_score=0.5, booster='gbtree',\n",
              "                                          colsample_bylevel=1,\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=0.67, eta=0.05,\n",
              "                                          gamma=0, importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=6, min_child_weight=240,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='reg:squarederror',\n",
              "                                          random_state=100,...\n",
              "                                          colsample_bynode=1,\n",
              "                                          colsample_bytree=0.67, eta=0.05,\n",
              "                                          gamma=0, importance_type='gain',\n",
              "                                          learning_rate=0.1, max_delta_step=0,\n",
              "                                          max_depth=6, min_child_weight=240,\n",
              "                                          missing=None, n_estimators=100,\n",
              "                                          n_jobs=1, nthread=None,\n",
              "                                          objective='count:poisson',\n",
              "                                          random_state=100, reg_alpha=0,\n",
              "                                          reg_lambda=1, scale_pos_weight=1,\n",
              "                                          seed=None, silent=None, subsample=0.9,\n",
              "                                          verbosity=1))],\n",
              "                n_jobs=-1, weights=[1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPIgIgn-8r3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "54e99e42-e91c-4e1a-be23-602fd5b11243"
      },
      "source": [
        "# model evaluation for regressor\n",
        "train_preds = ensemble.predict(df_Xtrain)\n",
        "test_preds = ensemble.predict(df_Xtest)\n",
        "\n",
        "train_kappa = eval_wrapper(ytrain,train_preds)\n",
        "test_kappa = eval_wrapper(ytest, test_preds)\n",
        "\n",
        "row = ['ensemble', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "\n",
        "# model evaluation for offset\n",
        "train_preds = apply_offsets(offsets,train_preds)\n",
        "train_kappa = eval_wrapper(ytrain,train_preds)\n",
        "\n",
        "test_preds = apply_offsets(offsets,test_preds)\n",
        "test_kappa = eval_wrapper(ytest,test_preds)\n",
        "\n",
        "row = ['ensemble + offset', train_kappa, test_kappa ]\n",
        "df_eval.loc[len(df_eval)] = row\n",
        "df_eval = df_eval.drop_duplicates()\n",
        "df_eval.style.background_gradient(subset=['TestKappa'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row0_col2 {\n",
              "            background-color:  #dddbec;\n",
              "            color:  #000000;\n",
              "        }    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row1_col2 {\n",
              "            background-color:  #03456c;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row2_col2 {\n",
              "            background-color:  #bfc9e1;\n",
              "            color:  #000000;\n",
              "        }    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row3_col2 {\n",
              "            background-color:  #023858;\n",
              "            color:  #f1f1f1;\n",
              "        }    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row4_col2 {\n",
              "            background-color:  #fff7fb;\n",
              "            color:  #000000;\n",
              "        }    #T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row5_col2 {\n",
              "            background-color:  #04649e;\n",
              "            color:  #f1f1f1;\n",
              "        }</style><table id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Model</th>        <th class=\"col_heading level0 col1\" >TrainKappa</th>        <th class=\"col_heading level0 col2\" >TestKappa</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row0_col0\" class=\"data row0 col0\" >xgb reg</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.669183</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.604010</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row1_col0\" class=\"data row1 col0\" >xgb reg + offset</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.720997</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.651084</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row2_col0\" class=\"data row2 col0\" >xgb poisson</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row2_col1\" class=\"data row2 col1\" >0.681906</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0.610618</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row3_col0\" class=\"data row3 col0\" >xgb poisson + offset</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row3_col1\" class=\"data row3 col1\" >0.734726</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row3_col2\" class=\"data row3 col2\" >0.654119</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row4_col0\" class=\"data row4 col0\" >ensemble</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row4_col1\" class=\"data row4 col1\" >0.627622</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row4_col2\" class=\"data row4 col2\" >0.591872</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row5_col0\" class=\"data row5 col0\" >ensemble + offset</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0.683484</td>\n",
              "                        <td id=\"T_4966c1ea_b322_11ea_a5f1_0242ac1c0002row5_col2\" class=\"data row5 col2\" >0.642557</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7fb49cef1a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6As0O4w_ulJK",
        "colab_type": "text"
      },
      "source": [
        "# Time Taken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g6SwCZr1WH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_taken = time.time() - time_start_notebook\n",
        "h,m = divmod(time_taken,60*60)\n",
        "print('Time taken to run whole notebook: {:.0f} hr '\\\n",
        "      '{:.0f} min {:.0f} secs'.format(h, *divmod(m,60)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}